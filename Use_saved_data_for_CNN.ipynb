{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Use_saved_data_for_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1TTUIgdoVBQY5NrvfnpmgHuQ3EGlBbFQt",
      "authorship_tag": "ABX9TyNgAyeZPtfb74ayTnSqenRr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "I have augmented the images that I will be classifying.  I created a function to resize, grayscale, and normalize the pixel values of each image.  Then I created a dataframe combining the images with their labels.  This uncovered the fact that about 9,000 of the 50,000 images were mislabeled.  The jpg name of the image could not find a partner jpg name in the labels csv provided.\n",
        "\n",
        "Using the reduced data set, I split the data into stratified test and validation sets and saved them to disk as numpy arrays. The data started at over 11 Gbs in size which caused RAM issues on my local machine of only 16 Gb RAM. I could load the data but would run out of memory when trying to manipulate it. I solved this by using Google Colab Pro, which provides me with 25 GB of RAM.  This is still not enough to manipulate the data as much as I would like, but I have been working around it by making one change and saving it, then uploading that data to a new notebook with a fresh 25 GB to start.  My final training data is about 9 GB in size.  I may need to augment the images further through rotations and/or larger sizes to get more detail, but that will require even more RAM so I will start with the 9GB set.\n",
        "\n",
        "I have created a base model with 94% training accuracy but only 67% validation accuracy.  The model is overfitting, but it gives me a starting point.\n",
        "\n",
        "Changing leaky Relu to Relu improved validation accuracy to 70%\n",
        "\n",
        "Dense layer neurons from 3,000 to 300 reduced validation accuracy to 69%\n",
        "\n",
        "Reducing layers from 3 to 2 convolutional and pooling reduced validation accuracy to 65%\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QsYh9oc7k7LC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lElzJZ3RKemg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import asarray\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=np.load('drive/MyDrive/X_train_strat.npy')"
      ],
      "metadata": {
        "id": "DEAUNeELMeaG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=np.load('drive/MyDrive/y_train_strat.npy')"
      ],
      "metadata": {
        "id": "GNPlaP3rM5wK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val=np.load('drive/MyDrive/X_val_strat.npy')"
      ],
      "metadata": {
        "id": "9X7YELBbidrY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val=np.load('drive/MyDrive/y_val_strat.npy')"
      ],
      "metadata": {
        "id": "6eH-O8hdid44"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei88D6ySNJ83",
        "outputId": "3404bd09-6689-4a41-8d39-dcb24a128c7c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((33089, 150, 200), (33089, 28))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Baseline Model\n",
        "\n",
        "# from tensorflow.keras import layers\n",
        "# from keras.models import Sequential,Input,Model\n",
        "# from keras.layers import Dense, Dropout, Flatten\n",
        "# from keras.layers import Conv2D, MaxPooling2D\n",
        "# from keras.layers.advanced_activations import LeakyReLU\n",
        "\n",
        "# model = keras.models.Sequential()\n",
        "# model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(150,200,1),padding='same'))\n",
        "# model.add(LeakyReLU(alpha=0.1))\n",
        "# model.add(MaxPooling2D((2, 2),padding='same'))\n",
        "# model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
        "# model.add(LeakyReLU(alpha=0.1))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "# model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
        "# model.add(LeakyReLU(alpha=0.1))                  \n",
        "# model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(3000, activation='linear'))\n",
        "# model.add(LeakyReLU(alpha=0.1))                  \n",
        "# model.add(Dense(28, activation='softmax'))"
      ],
      "metadata": {
        "id": "EyHCmOTHNM7S"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wa_pdmR7OBWf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## model.fit(X_train, y_train,batch_size=30, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cchgS0GzOQat",
        "outputId": "2a4ba25d-89a4-4ed3-e7d1-f399c5abfd51"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1103/1103 [==============================] - 56s 39ms/step - loss: 1.4638 - accuracy: 0.5738\n",
            "Epoch 2/5\n",
            "1103/1103 [==============================] - 43s 39ms/step - loss: 0.9173 - accuracy: 0.7120\n",
            "Epoch 3/5\n",
            "1103/1103 [==============================] - 44s 39ms/step - loss: 0.5395 - accuracy: 0.8241\n",
            "Epoch 4/5\n",
            "1103/1103 [==============================] - 43s 39ms/step - loss: 0.2643 - accuracy: 0.9122\n",
            "Epoch 5/5\n",
            "1103/1103 [==============================] - 43s 39ms/step - loss: 0.1778 - accuracy: 0.9439\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fee201680d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##model.evaluate(X_val,y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJXe5380PyzS",
        "outputId": "ee947952-f675-4575-d71e-3f8a9e473774"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "259/259 [==============================] - 3s 11ms/step - loss: 1.8553 - accuracy: 0.6786\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.855276346206665, 0.6785930395126343]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Baseline model not stratified.  Training accuracy 0.95   evaluation accuracy 0.65\n",
        "##### Stratified Baseline model       Training accuracy 0.94   evaluation accuracy 0.67\n",
        "##### Stratified Relu, not leaky relu Training accuracy 0.96   evaluation accuracy 0.70"
      ],
      "metadata": {
        "id": "Aqm437sOhzpn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model2  not leaky Relu"
      ],
      "metadata": {
        "id": "REtxiNCii20p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "model2 = keras.models.Sequential()\n",
        "model2.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(150,200,1),padding='same'))\n",
        "model2.add(MaxPooling2D((2, 2),padding='same'))\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu',padding='same'))                 \n",
        "model2.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(3000, activation='relu'))               \n",
        "model2.add(Dense(28, activation='softmax'))"
      ],
      "metadata": {
        "id": "qVzLD-txWfLK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "uyA2sDY3cdyI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(X_train, y_train,batch_size=30, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "7CDyz1qrcd0W",
        "outputId": "eaccc7ab-cc8a-4b0b-ca2d-1766cd264ca1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InternalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-db559ab3de06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate(X_val,y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiQQA5Q7cd2O",
        "outputId": "f9e956bf-b945-4f60-a38f-799a186812bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "259/259 [==============================] - 3s 11ms/step - loss: 1.6980 - accuracy: 0.7037\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6980047225952148, 0.7037350535392761]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P2tUJ0XPcd50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model3"
      ],
      "metadata": {
        "id": "emQ6cp9Ci90b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "model3 = keras.models.Sequential()\n",
        "model3.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(150,200,1),padding='same'))\n",
        "model3.add(MaxPooling2D((2, 2),padding='same'))\n",
        "model3.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "model3.add(Conv2D(128, (3, 3), activation='relu',padding='same'))                 \n",
        "model3.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(300, activation='relu'))               \n",
        "model3.add(Dense(28, activation='softmax'))"
      ],
      "metadata": {
        "id": "t8NIOYCfjADb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "u5_HgisOpAvW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.fit(X_train, y_train,batch_size=30, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H5bfQslpA0K",
        "outputId": "c3ade789-4704-46bf-94a1-ae0c1bb46182"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1103/1103 [==============================] - 45s 26ms/step - loss: 1.4102 - accuracy: 0.5813\n",
            "Epoch 2/5\n",
            "1103/1103 [==============================] - 28s 26ms/step - loss: 0.8974 - accuracy: 0.7198\n",
            "Epoch 3/5\n",
            "1103/1103 [==============================] - 28s 26ms/step - loss: 0.5801 - accuracy: 0.8146\n",
            "Epoch 4/5\n",
            "1103/1103 [==============================] - 28s 26ms/step - loss: 0.2879 - accuracy: 0.9052\n",
            "Epoch 5/5\n",
            "1103/1103 [==============================] - 28s 25ms/step - loss: 0.1295 - accuracy: 0.9584\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ffae066ddd0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.evaluate(X_val,y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_Rl-HhruOSC",
        "outputId": "1b6b3806-159b-4a32-ec21-b5ac0170e44f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "259/259 [==============================] - 3s 11ms/step - loss: 1.5444 - accuracy: 0.6983\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.544400691986084, 0.6982956528663635]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Fd4Y_lG6uP_g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}